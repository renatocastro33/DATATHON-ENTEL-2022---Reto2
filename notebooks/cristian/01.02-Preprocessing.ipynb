{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a812de94",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "914b6400",
     "kernelId": "2916018f-6766-4ce9-a9f0-c3eb16ceb4f1",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../../Src')\n",
    "from utils.preprocessing import *\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys, gc, time, warnings, pickle, psutil, random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from joblib import Parallel, delayed\n",
    "from math import ceil\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import gc\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "SEED = 42\n",
    "seed_everything(SEED)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "SHIFT_DAY = 1\n",
    "WINDOW = 15\n",
    "TARGET = 'Demanda'         # Our main target\n",
    "PATH_DATASET = '../../dataset/'\n",
    "PATH_RESULTS = '../../results/Demanda/'\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_theme(style=\"ticks\", color_codes=True)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "gc.collect()\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a269ceb",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "2b0d2fad",
     "kernelId": "2916018f-6766-4ce9-a9f0-c3eb16ceb4f1"
    }
   },
   "source": [
    "# loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e6a2871",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "1d92c12b",
     "kernelId": "2916018f-6766-4ce9-a9f0-c3eb16ceb4f1",
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle(os.path.join(PATH_RESULTS,'dataset','df_train.pkl'))\n",
    "df_test  = pd.read_pickle(os.path.join(PATH_RESULTS,'dataset','df_test.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cfa54da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.replace([np.inf, -np.inf, np.nan],0,inplace=True)\n",
    "df_test.replace([np.inf, -np.inf, np.nan],0,inplace=True)\n",
    "\n",
    "N_test  = df_test.shape[0]\n",
    "N_train = df_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80b00688",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['DATE'] = pd.to_datetime(df_train['Z_WEEK_DATE'], errors='coerce')\n",
    "df_test['DATE']  = pd.to_datetime(df_test['Z_WEEK_DATE'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c3c84e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2830380, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_aux = pd.read_pickle(os.path.join(PATH_RESULTS,'dataset','df_train.pkl'))\n",
    "df_test_aux  = pd.read_pickle(os.path.join(PATH_RESULTS,'dataset','df_test.pkl'))    \n",
    "\n",
    "df_auxiliar = pd.concat([df_train_aux,df_test_aux])\n",
    "\n",
    "df_auxiliar.replace([np.inf, -np.inf,np.nan],0 , inplace=True)\n",
    "df_auxiliar.reset_index(inplace=True,drop=True)\n",
    "print(df_auxiliar.shape)\n",
    "df_auxiliar.head(2)\n",
    "\n",
    "df_auxiliar['Z_WEEK_DATE']  = pd.to_datetime(df_auxiliar['Z_WEEK_DATE'], errors='coerce')\n",
    "\n",
    "del df_train_aux\n",
    "del df_test_aux\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f151e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_train['Z_WEEK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbbbebac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 215.94 MB\n",
      "Memory usage after optimization is: 98.58 MB\n",
      "Decreased by 54.4%\n",
      "********************\n",
      "********************\n"
     ]
    }
   ],
   "source": [
    "df_auxiliar = reduce_mem_usage(df_auxiliar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "743984f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auxiliar[\"item_id\"] = df_auxiliar[\"Z_MODELO\"].astype(str) +\"|\"+ df_auxiliar[\"Z_PUNTO_VENTA\"].astype(str) +\"|\"+ df_auxiliar[\"Z_GAMA\"].astype(str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92fb1033",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"item_id\"] = df_train[\"Z_MODELO\"].astype(str) +\"|\"+ df_train[\"Z_PUNTO_VENTA\"].astype(str) +\"|\"+ df_train[\"Z_GAMA\"].astype(str) \n",
    "df_test[\"item_id\"]  = df_test[\"Z_MODELO\"].astype(str) +\"|\"+ df_test[\"Z_PUNTO_VENTA\"].astype(str) +\"|\"+ df_test[\"Z_GAMA\"].astype(str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bdfc4e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auxiliar.sort_values(by=['item_id','Z_WEEK_DATE'], ascending=[True, True],inplace=True)\n",
    "df_test.sort_values(by=['item_id','Z_WEEK_DATE'], ascending=[True, True],inplace=True)\n",
    "df_train.sort_values(by=['item_id','Z_WEEK_DATE'], ascending=[True, True],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ec6adf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Release week\n",
      "1 df_auxiliar (2830380, 10)\n",
      "2 df_auxiliar (2830380, 11)\n"
     ]
    }
   ],
   "source": [
    "########################### Product Release date\n",
    "#################################################################################\n",
    "print('Release week')\n",
    "\n",
    "release_df = df_train[['item_id','date_block_num']][df_train[TARGET]>0].groupby(['item_id'])['date_block_num'].agg(['min']).reset_index()\n",
    "release_df.columns = ['item_id','release']\n",
    "print('1 df_auxiliar',df_auxiliar.shape)\n",
    "df_auxiliar = merge_by_concat(df_auxiliar, release_df, ['item_id'])\n",
    "print('2 df_auxiliar',df_auxiliar.shape)\n",
    "del release_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb918870",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auxiliar['release'].fillna(100.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4b320bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auxiliar['release'] = df_auxiliar['release'].astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91e67da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 df_auxiliar (2830380, 11)\n"
     ]
    }
   ],
   "source": [
    "df_auxiliar = df_auxiliar.reset_index(drop=True)\n",
    "print('3 df_auxiliar',df_auxiliar.shape)\n",
    "\n",
    "df_auxiliar['release'] = df_auxiliar['release'] - df_auxiliar['release'].min()\n",
    "df_auxiliar['release'] = df_auxiliar['release'].astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70450522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6fdf4a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save Part 1\n",
      "Size: (2830380, 11)\n"
     ]
    }
   ],
   "source": [
    "########################### Save part 1\n",
    "#################################################################################\n",
    "print('Save Part 1')\n",
    "df_auxiliar.to_pickle(os.path.join(PATH_RESULTS,'dataset','grid_part_1.pkl'))\n",
    "print('Size:', df_auxiliar.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76f8c98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END_TRAIN  : 59\n"
     ]
    }
   ],
   "source": [
    "########################### Vars\n",
    "#################################################################################\n",
    "END_TRAIN = df_auxiliar['date_block_num'].max()         # Last day in train set\n",
    "print('END_TRAIN  :',END_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f97eaa4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET     : Demanda\n",
      "END_TRAIN  : 59\n",
      "MAIN_INDEX : ['item_id', 'date_block_num']\n"
     ]
    }
   ],
   "source": [
    "MAIN_INDEX = ['item_id','date_block_num']  # We can identify item by these columns\n",
    "print('TARGET     :',TARGET)\n",
    "print('END_TRAIN  :',END_TRAIN)\n",
    "print('MAIN_INDEX :',MAIN_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9da34125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TRAIN  : 0\n"
     ]
    }
   ],
   "source": [
    "START_TRAIN = df_auxiliar['date_block_num'].min()         # First day in train set\n",
    "print('START_TRAIN  :',START_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e376757e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_auxiliar (2830380, 3)\n"
     ]
    }
   ],
   "source": [
    "#df_auxiliar = pd.read_pickle(os.path.join(PATH_RESULTS,'dataset','grid_part_1.pkl'))\n",
    "    \n",
    "df_train_aux = pd.read_pickle(os.path.join(PATH_RESULTS,'dataset','df_train.pkl'))\n",
    "df_test_aux  = pd.read_pickle(os.path.join(PATH_RESULTS,'dataset','df_test.pkl'))    \n",
    "\n",
    "df_auxiliar = pd.concat([df_train_aux,df_test_aux])\n",
    "    \n",
    "df_auxiliar = df_auxiliar[['Z_WEEK_DATE', 'item_id', 'date_block_num']]\n",
    "print('df_auxiliar',df_auxiliar.shape)\n",
    "df_auxiliar             = fe_dates(\"Z_WEEK_DATE\",df_auxiliar)\n",
    "\n",
    "df_auxiliar['tm_wm']    = df_auxiliar['day'].apply(lambda x: ceil(x/7)).astype(np.int8) # 오늘 몇째주?\n",
    "df_auxiliar['tm_w_end'] = (df_auxiliar['day_of_week']>=5).astype(np.int8)\n",
    "df_auxiliar['tm_m_end'] = (df_auxiliar['tm_wm']>=3).astype(np.int8)\n",
    "del df_auxiliar['Z_WEEK_DATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "249ba236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ceb0662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save part 2\n",
      "Size: (2830380, 14)\n"
     ]
    }
   ],
   "source": [
    "########################### Save part 2 (Dates)\n",
    "#################################################################################\n",
    "print('Save part 2')\n",
    "\n",
    "# Safe part 3\n",
    "df_auxiliar.to_pickle(os.path.join(PATH_RESULTS,'dataset','grid_part_2.pkl'))\n",
    "print('Size:', df_auxiliar.shape)\n",
    "\n",
    "# We don't need calendar_df anymore\n",
    "del df_auxiliar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41d1987e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_df = pd.read_pickle(os.path.join(PATH_RESULTS,'dataset','grid_part_1.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01294491",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_df = grid_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31eb8bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_df.sort_values(by=['item_id','Z_WEEK_DATE'], ascending=[True, True],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73fb3b1-a448-4648-8289-2c9425d6f427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lags\n",
    "# with 28 day shift\n",
    "start_time = time.time()\n",
    "print('Create lags')\n",
    "\n",
    "\n",
    "LAG_DAYS = [col for col in range(SHIFT_DAY,SHIFT_DAY+WINDOW)]\n",
    "print('len LAG_DAYS',len(LAG_DAYS))\n",
    "grid_df = grid_df.assign(**{\n",
    "        '{}_lag_shift_{}'.format(col, l): grid_df.groupby(['item_id'])[col].transform(lambda x: x.shift(l))\n",
    "        for l in LAG_DAYS\n",
    "        for col in [TARGET]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c2370fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_df.replace([np.inf, -np.inf,np.nan],0 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "24b71ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_df (2830380, 26)\n"
     ]
    }
   ],
   "source": [
    "print('grid_df',grid_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "522da740",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_df.replace([np.inf, -np.inf, np.nan],0,inplace=True)\n",
    "grid_df = grid_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bad43fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f817a887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.23 min: Lags\n"
     ]
    }
   ],
   "source": [
    "# Minify lag columns\n",
    "for col in list(grid_df):\n",
    "    if 'lag' in col:\n",
    "        grid_df[col] = grid_df[col].astype(np.float16)\n",
    "\n",
    "print('%0.2f min: Lags' % ((time.time() - start_time) / 60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b9d4dac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_df[['Z_MODELO', 'Z_PUNTO_VENTA', 'Z_GAMA']] = grid_df['item_id'].str.split('|',expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0891cb01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create rolling aggs\n",
      "Shifting period: 1\n",
      "Shifting period: 2\n",
      "Shifting period: 3\n",
      "Shifting period: 4\n",
      "Shifting period: 5\n",
      "Shifting period: 6\n",
      "Shifting period: 7\n",
      "Shifting period: 8\n",
      "Shifting period: 9\n",
      "Shifting period: 10\n",
      "Shifting period: 11\n",
      "Shifting period: 12\n",
      "Shifting period: 13\n",
      "Shifting period: 14\n",
      "Shifting period: 15\n",
      "Shifting period: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [04:03<00:00,  4.21it/s]\n",
      "100%|██████████| 1024/1024 [00:03<00:00, 330.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.57 min: Lags\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "icols =  [  ['item_id'],\n",
    "            ['Z_MODELO'],\n",
    "            ['Z_PUNTO_VENTA'],\n",
    "            ['Z_GAMA'],\n",
    "            ['Z_MARCA'],\n",
    "            ['Z_DEPARTAMENTO'],\n",
    "    \n",
    "            ['Z_MODELO', 'Z_PUNTO_VENTA'],\n",
    "          \n",
    "            ['Z_MODELO', 'Z_GAMA'],\n",
    "            ['Z_MODELO', 'Z_MARCA'],\n",
    "            ['Z_MODELO', 'Z_DEPARTAMENTO'],\n",
    "    \n",
    "            ['Z_PUNTO_VENTA', 'Z_GAMA'],\n",
    "            ['Z_PUNTO_VENTA', 'Z_MARCA'],\n",
    "            ['Z_PUNTO_VENTA', 'Z_DEPARTAMENTO'],\n",
    "    \n",
    "            ['Z_GAMA', 'Z_MARCA'],\n",
    "            ['Z_GAMA', 'Z_DEPARTAMENTO'],\n",
    "    \n",
    "            ['Z_MARCA', 'Z_DEPARTAMENTO'],\n",
    "        \n",
    "            ]\n",
    "# Rollings\n",
    "start_time = time.time()\n",
    "print('Create rolling aggs')\n",
    "global grid_df\n",
    "# Rollings\n",
    "# with sliding shift\n",
    "\n",
    "\n",
    "total_combinations = []\n",
    "for d_shift in range(SHIFT_DAY,SHIFT_DAY+WINDOW+1): \n",
    "    print('Shifting period:', d_shift)\n",
    "    for d_window in [2,4]:\n",
    "        col_name = 'shift_'+str(d_shift)+'_roll_'+str(d_window)\n",
    "        for group_columns in icols:\n",
    "            for tipo in ['mean','std']:\n",
    "                total_combinations.append([d_shift,d_window,group_columns,tipo])\n",
    "\n",
    "\n",
    "def process_lags(x):\n",
    "    global grid_df\n",
    "    d_shift = x[0]\n",
    "    d_window = x[1]\n",
    "    group_columns = x[2]\n",
    "    tipo = x[3]\n",
    "    col_name = 'shift_'+str(d_shift)+'_roll_'+str(d_window)\n",
    "    if tipo == 'mean':\n",
    "        var = grid_df.groupby(group_columns)[TARGET].transform(lambda x: x.shift(d_shift).fillna(0).rolling(d_window,min_periods=1).mean()).astype(np.float16)\n",
    "        return [col_name+'_mean_'+'_'.join(group_columns),var]\n",
    "    if tipo == 'std':\n",
    "        var = grid_df.groupby(group_columns)[TARGET].transform(lambda x: x.shift(d_shift).fillna(0).rolling(d_window,min_periods=1).std(ddof=0)).astype(np.float16)\n",
    "        return [col_name+'_std_'+'_'.join(group_columns),var]\n",
    "    if tipo == 'max':\n",
    "        var = grid_df.groupby(group_columns)[TARGET].transform(lambda x: x.shift(d_shift).fillna(0).rolling(d_window,min_periods=1).max()).astype(np.float16)\n",
    "        return [col_name+'_std_'+'_'.join(group_columns),var]\n",
    "\n",
    "\n",
    "\n",
    "#results = pqdm(total_combinations, process_lags, n_jobs=8)\n",
    "results = Parallel(n_jobs=8, batch_size=64, backend=\"loky\", verbose=0)(delayed(process_lags)(n) for n in tqdm(total_combinations))\n",
    "n= len(results)\n",
    "\n",
    "for i in tqdm(range(n)):\n",
    "    va = results.pop()\n",
    "    grid_df[va[0]] = va[1]    \n",
    "    \n",
    "print('%0.2f min: Lags' % ((time.time() - start_time) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8099b31c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10984"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del results\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a63b89d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del grid_df['Z_MODELO']\n",
    "del grid_df['Z_PUNTO_VENTA']\n",
    "del grid_df['Z_GAMA']\n",
    "del grid_df['Z_MARCA']\n",
    "del grid_df['Z_DEPARTAMENTO']\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7f0e5308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save lags and rollings\n",
      "../Results/Demanda/dataset/lags_df_1_completed.pkl\n"
     ]
    }
   ],
   "source": [
    "########################### Export\n",
    "#################################################################################\n",
    "print('Save lags and rollings')\n",
    "print(os.path.join(PATH_RESULTS,'dataset','lags_df_'+str(SHIFT_DAY)+'_completed.pkl'))\n",
    "grid_df.to_pickle(os.path.join(PATH_RESULTS,'dataset','lags_df_'+str(SHIFT_DAY)+'_completed.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8bb6b133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: (2830380, 1045)\n"
     ]
    }
   ],
   "source": [
    "print('Size:', grid_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bf0bb6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Apply on grid_df\n",
    "#################################################################################\n",
    "# lets read grid from \n",
    "# https://www.kaggle.com/kyakovlev/m5-simple-fe\n",
    "# to be sure that our grids are aligned by index\n",
    "grid_df = pd.read_pickle(os.path.join(PATH_RESULTS,'dataset','grid_part_1.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5bdd6c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding ['Z_MODELO']\n",
      "Encoding ['Z_PUNTO_VENTA']\n",
      "Encoding ['Z_GAMA']\n",
      "Encoding ['Z_MARCA']\n",
      "Encoding ['Z_DEPARTAMENTO']\n",
      "Encoding ['Z_MODELO', 'Z_PUNTO_VENTA']\n",
      "Encoding ['Z_MODELO', 'Z_GAMA']\n",
      "Encoding ['Z_MODELO', 'Z_MARCA']\n",
      "Encoding ['Z_MODELO', 'Z_DEPARTAMENTO']\n",
      "Encoding ['Z_PUNTO_VENTA', 'Z_GAMA']\n",
      "Encoding ['Z_PUNTO_VENTA', 'Z_MARCA']\n",
      "Encoding ['Z_PUNTO_VENTA', 'Z_DEPARTAMENTO']\n",
      "Encoding ['Z_GAMA', 'Z_MARCA']\n",
      "Encoding ['Z_GAMA', 'Z_DEPARTAMENTO']\n",
      "Encoding ['Z_MARCA', 'Z_DEPARTAMENTO']\n",
      "Encoding ['Z_MODELO', 'Z_PUNTO_VENTA', 'Z_GAMA']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "grid_df[TARGET][grid_df['date_block_num']>(END_TRAIN-10)] = np.nan\n",
    "base_cols = list(grid_df)\n",
    "\n",
    "icols =  [\n",
    "            ['Z_MODELO'],\n",
    "            ['Z_PUNTO_VENTA'],\n",
    "            ['Z_GAMA'],\n",
    "            ['Z_MARCA'],\n",
    "            ['Z_DEPARTAMENTO'],\n",
    "    \n",
    "            ['Z_MODELO', 'Z_PUNTO_VENTA'],\n",
    "            ['Z_MODELO', 'Z_GAMA'],\n",
    "            ['Z_MODELO', 'Z_MARCA'],\n",
    "            ['Z_MODELO', 'Z_DEPARTAMENTO'],\n",
    "    \n",
    "            ['Z_PUNTO_VENTA', 'Z_GAMA'],\n",
    "            ['Z_PUNTO_VENTA', 'Z_MARCA'],\n",
    "            ['Z_PUNTO_VENTA', 'Z_DEPARTAMENTO'],\n",
    "    \n",
    "            ['Z_GAMA', 'Z_MARCA'],\n",
    "            ['Z_GAMA', 'Z_DEPARTAMENTO'],\n",
    "    \n",
    "            ['Z_MARCA', 'Z_DEPARTAMENTO'],\n",
    "        \n",
    "            ['Z_MODELO', 'Z_PUNTO_VENTA', 'Z_GAMA'],\n",
    "            ]\n",
    "\n",
    "for col in icols:\n",
    "    print('Encoding', col)\n",
    "    col_name = '_'+'_'.join(col)+'_'\n",
    "    grid_df['enc'+col_name+'mean'] = grid_df.groupby(col)[TARGET].transform('mean').astype(np.float32)\n",
    "    grid_df['enc'+col_name+'std'] = grid_df.groupby(col)[TARGET].transform('std').astype(np.float32)\n",
    "    #grid_df['enc'+col_name+'sum'] = grid_df.groupby(col)[TARGET].transform('sum').astype(np.float32)\n",
    "    #grid_df['enc'+col_name+'count'] = grid_df.groupby(col)[TARGET].transform('count').astype(np.float32)\n",
    "    grid_df['enc'+col_name+'max'] = grid_df.groupby(col)[TARGET].transform('max').astype(np.float32)\n",
    "    #grid_df['enc'+col_name+'min'] = grid_df.groupby(col)[TARGET].transform('min').astype(np.float32)\n",
    "keep_cols = [col for col in list(grid_df) if col not in base_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6c774cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cols = [col for col in list(grid_df) if col not in base_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3b5dab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_df = grid_df[['Z_WEEK_DATE', 'item_id', 'date_block_num']+keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fc1ed41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save Mean/Std encoding\n",
      "../Results/Demanda/dataset/mean_encoding_df.pkl\n"
     ]
    }
   ],
   "source": [
    "#################################################################################\n",
    "print('Save Mean/Std encoding')\n",
    "print(os.path.join(PATH_RESULTS,'dataset','mean_encoding_df.pkl'))\n",
    "grid_df.to_pickle(os.path.join(PATH_RESULTS,'dataset','mean_encoding_df.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c361d25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61c90a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
